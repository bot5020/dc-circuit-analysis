"""C–∫—Ä–∏–ø—Ç –æ—Ü–µ–Ω–∫–∏ –º–æ–¥–µ–ª–µ–π –¥–ª—è DC Circuit Analysis.

–¢–µ—Å—Ç–∏—Ä—É–µ—Ç —Ç—Ä–∏ –ø–æ–¥—Ö–æ–¥–∞:
1. Zero-shot - –±–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å –±–µ–∑ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞
2. Prompt Engineering - –º–æ–¥–µ–ª—å —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º —Å–∏—Å—Ç–µ–º–Ω—ã–º –ø—Ä–æ–º–ø—Ç–æ–º
3. GRPO Trained - –æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å —Å LoRA
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from typing import List, Dict
import re
import torch
from unsloth import FastLanguageModel
from vllm import LLM, SamplingParams

from base.data import Data
from dc_circuit.game import DCCircuitGame
from config import CircuitConfig, VerifierConfig, TrainingConfig
from base.utils import get_system_prompt



class Evaluator:
    """–û—Ü–µ–Ω—â–∏–∫ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π."""

    
    def __init__(
        self,
        baseline_model: str = "unsloth/Qwen2.5-0.5B",
        trained_model_path: str = "./dc_circuit_model_rl",
        samples_per_difficulty: int = 5
    ):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ—Ü–µ–Ω—â–∏–∫–∞.
        
        Args:
            baseline_model: –ù–∞–∑–≤–∞–Ω–∏–µ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏
            trained_model_path: –ü—É—Ç—å –∫ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
            samples_per_difficulty: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–¥–∞—á –Ω–∞ —É—Ä–æ–≤–µ–Ω—å —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
        """
        self.baseline_model_name = baseline_model
        self.trained_model_path = trained_model_path
        self.samples_per_difficulty = samples_per_difficulty
        
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        self.circuit_config = CircuitConfig()
        self.verifier_config = VerifierConfig()
        self.training_config = TrainingConfig()
        
        # Game –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏ –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏
        self.game = DCCircuitGame(self.circuit_config, self.verifier_config)

    def _has_strict_answer_format(self, response: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—Ç—Ä–æ–≥–∏–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ –≤ <answer>: —Ä–æ–≤–Ω–æ —á–∏—Å–ª–æ —Å 3 –∑–Ω–∞–∫–∞–º–∏.

        –£—Å–ª–æ–≤–∏—è:
        - –í —Ç–µ–∫—Å—Ç–µ –µ—Å—Ç—å —Ç–µ–≥–∏ <answer>...</answer>
        - –í–Ω—É—Ç—Ä–∏ —Ä–æ–≤–Ω–æ –æ–¥–Ω–æ —á–∏—Å–ª–æ —Ñ–æ—Ä–º–∞—Ç–∞ X.XXX (3 –¥–µ—Å—è—Ç–∏—á–Ω—ã—Ö –∑–Ω–∞–∫–∞)
        - –ù–µ—Ç –µ–¥–∏–Ω–∏—Ü –∏–∑–º–µ—Ä–µ–Ω–∏—è –∏ –ª–∏—à–Ω–µ–≥–æ —Ç–µ–∫—Å—Ç–∞
        """
        if not response:
            return False
        # –ù–∞–π—Ç–∏ –ø–æ—Å–ª–µ–¥–Ω–∏–π <answer>...</answer>
        tag_matches = re.findall(r"<answer>([\s\S]*?)</answer>", response, flags=re.IGNORECASE)
        if not tag_matches:
            return False
        content = tag_matches[-1].strip()
        # –î–æ–ª–∂–Ω–æ –±—ã—Ç—å —Å—Ç—Ä–æ–≥–æ —á–∏—Å–ª–æ —Å 3 –¥–µ—Å—è—Ç–∏—á–Ω—ã–º–∏, –±–µ–∑ –µ–¥–∏–Ω–∏—Ü –∏ —Ç–µ–∫—Å—Ç–∞
        return bool(re.fullmatch(r"[-+]?\d+\.\d{3}", content))
        
    def generate_test_data(self) -> Dict[int, List[Data]]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤—Å–µ—Ö —É—Ä–æ–≤–Ω–µ–π —Å–ª–æ–∂–Ω–æ—Å—Ç–∏.
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å {difficulty: list_of_data}
        """
        print("\nüìù –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
        test_data = {}
        
        for difficulty in [1, 2]:  
            print(f"  –°–ª–æ–∂–Ω–æ—Å—Ç—å {difficulty}: –≥–µ–Ω–µ—Ä–∞—Ü–∏—è {self.samples_per_difficulty} –∑–∞–¥–∞—á...")
            data_list = self.game.generate(
                num_of_questions=self.samples_per_difficulty,
                difficulty=difficulty
            )
            test_data[difficulty] = data_list
            print(f"    ‚úì –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(data_list)} –∑–∞–¥–∞—á")
        
        total = sum(len(data) for data in test_data.values())
        print(f"  –í—Å–µ–≥–æ —Ç–µ—Å—Ç–æ–≤—ã—Ö –∑–∞–¥–∞—á: {total}\n")
        
        return test_data
    
    def load_model(self, model_path: str, is_trained: bool = False):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å —á–µ—Ä–µ–∑ vLLM.
        
        Args:
            model_path: –ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏
            is_trained: True –µ—Å–ª–∏ —ç—Ç–æ –æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å —Å LoRA
        
        Returns:
            (llm, sampling_params)
        """
        print(f"üì• –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ vLLM: {model_path}")
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ vLLM
        llm = LLM(
            model=model_path,
            max_model_len=self.training_config.max_seq_length,
            dtype='bfloat16',
            gpu_memory_utilization=self.DEFAULT_GPU_MEMORY_UTILIZATION,
            trust_remote_code=True,
            enforce_eager=False
        )
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–µ–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏—è
        sampling_params = SamplingParams(
            temperature=self.DEFAULT_TEMPERATURE,
            max_tokens=self.training_config.max_completion_length,
            stop=["<|im_end|>", "</s>"]
        )
        
        print(f"  ‚úì –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —á–µ—Ä–µ–∑ vLLM\n")
        return llm, sampling_params
    
    def generate_answer(
        self, 
        llm, 
        sampling_params, 
        question: str, 
        use_system_prompt: bool = True
    ) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏ –Ω–∞ –≤–æ–ø—Ä–æ—Å —á–µ—Ä–µ–∑ vLLM.
        
        Args:
            llm: vLLM –º–æ–¥–µ–ª—å
            sampling_params: –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–µ–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏—è
            question: –í–æ–ø—Ä–æ—Å
            use_system_prompt: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
        
        Returns:
            –û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏
        """
        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç
        if use_system_prompt:
            messages = [
                {"role": "system", "content": get_system_prompt()},
                {"role": "user", "content": question}
            ]
        else:
            # Zero-shot: —Ç–æ–ª—å–∫–æ –≤–æ–ø—Ä–æ—Å, –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç
            messages = [
                {"role": "system", "content": "You are a helpful assistant."},
                {"role": "user", "content": question}
            ]
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è vLLM (–ø—Ä–æ—Å—Ç–æ–π —Ñ–æ—Ä–º–∞—Ç)
        if use_system_prompt:
            prompt = f"<|im_start|>system\n{get_system_prompt()}<|im_end|>\n<|im_start|>user\n{question}<|im_end|>\n<|im_start|>assistant\n"
        else:
            prompt = f"<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n{question}<|im_end|>\n<|im_start|>assistant\n"
        
        # üîç –û–¢–õ–ê–î–û–ß–ù–´–ô –í–´–í–û–î –ì–ï–ù–ï–†–ê–¶–ò–ò
        print(f"\nüîß –û–¢–õ–ê–î–ö–ê –ì–ï–ù–ï–†–ê–¶–ò–ò:")
        print(f"üìù –ü–†–û–ú–ü–¢ (–ø–µ—Ä–≤—ã–µ 200 —Å–∏–º–≤–æ–ª–æ–≤): {prompt[:200]}...")
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç —á–µ—Ä–µ–∑ vLLM
        outputs = llm.generate([prompt], sampling_params)
        response = outputs[0].outputs[0].text
        
        print(f"ü§ñ –ü–û–õ–ù–´–ô –û–¢–í–ï–¢ –ú–û–î–ï–õ–ò:")
        print(f"{response}")
        print(f"üìè –î–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞: {len(response)} —Å–∏–º–≤–æ–ª–æ–≤")
        
        # –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –≤–µ—Å—å —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç,
        # –∏–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ —á–∞—Å—Ç—å –ø–æ—Å–ª–µ "assistant"
        if "assistant" in response and len(response) > 1000:
            # –ò—â–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π "assistant" –≤ –æ—Ç–≤–µ—Ç–µ
            assistant_parts = response.split("assistant")
            if len(assistant_parts) > 1:
                # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ —á–∞—Å—Ç—å –ø–æ—Å–ª–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ "assistant"
                response = assistant_parts[-1].strip()
                print(f"üîß –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ò–∑–≤–ª–µ—á–µ–Ω —Ç–æ–ª—å–∫–æ –æ—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞")
                print(f"‚úÇÔ∏è –§–ò–ù–ê–õ–¨–ù–´–ô –û–¢–í–ï–¢:")
                print(f"{response}")
        
        return response
    
    def evaluate_model_on_data(
        self,
        llm,
        sampling_params,
        test_data: Dict[int, List[Data]],
        method_name: str,
        use_system_prompt: bool = True
    ) -> Dict[int, Dict[str, float]]:
        """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç –º–æ–¥–µ–ª—å –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö.
        
        Args:
            llm: vLLM –º–æ–¥–µ–ª—å
            sampling_params: –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–µ–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏—è
            test_data: –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
            method_name: –ù–∞–∑–≤–∞–Ω–∏–µ –º–µ—Ç–æ–¥–∞ –¥–ª—è –≤—ã–≤–æ–¥–∞
            use_system_prompt: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å {difficulty: {"accuracy": float, "format_score": float, "strict_format_score": float}}
        """
        print(f"üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ: {method_name}")
        
        # üîç –û–¢–õ–ê–î–û–ß–ù–´–ô –í–´–í–û–î –°–ò–°–¢–ï–ú–ù–û–ì–û –ü–†–û–ú–ü–¢–ê
        if use_system_prompt:
            from base.utils import get_system_prompt
            system_prompt = get_system_prompt()
            print(f"\nüìã –°–ò–°–¢–ï–ú–ù–´–ô –ü–†–û–ú–ü–¢:")
            print("=" * 80)
            print(f"{system_prompt}")
            print("=" * 80)
        else:
            print(f"\nüìã –†–ï–ñ–ò–ú: Zero-shot (–±–µ–∑ —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞)")
        
        results = {}
        
        for difficulty, data_list in sorted(test_data.items()):
            correct = 0
            format_correct = 0
            strict_format_correct = 0
            total = len(data_list)
            
            for i, data in enumerate(data_list):
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
                response = self.generate_answer(
                    llm, sampling_params, data.question, use_system_prompt
                )
                
                # üîç –û–¢–õ–ê–î–û–ß–ù–´–ô –í–´–í–û–î
                print(f"\nüîç –û–¢–õ–ê–î–ö–ê –ó–ê–î–ê–ß–ò {i+1}/{total} (–°–ª–æ–∂–Ω–æ—Å—Ç—å {difficulty}):")
                print("=" * 80)
                print(f"üìã –ü–û–õ–ù–ê–Ø –ó–ê–î–ê–ß–ê:")
                print(f"{data.question}")
                print(f"\n‚úÖ –û–ñ–ò–î–ê–ï–ú–´–ô –û–¢–í–ï–¢: {data.answer}")
                print(f"\nü§ñ –û–¢–í–ï–¢ –ú–û–î–ï–õ–ò:")
                print(f"{response}")
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Ç–≤–µ—Ç –∏–∑ –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ–ª–∏
                from base.utils import extract_answer
                extracted_answer = extract_answer(response)
                print(f"\nüîç –ò–ó–í–õ–ï–ß–ï–ù–ù–´–ô –û–¢–í–ï–¢: '{extracted_answer}'")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å
                is_correct = self.game.verify(data, response)
                accuracy_score = self.game.verifier.get_accuracy_score(data, response)
                print(f"\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢ –í–ï–†–ò–§–ò–ö–ê–¶–ò–ò:")
                print(f"  –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π: {is_correct}")
                print(f"  Accuracy Score: {accuracy_score:.3f}")
                
                if is_correct:
                    correct += 1
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞
                has_think = "<think>" in response
                has_answer = "<answer>" in response
                format_ok = has_think and has_answer
                strict_format_ok = self._has_strict_answer_format(response)
                print(f"\nüìù –§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê:")
                print(f"  –ï—Å—Ç—å <think>: {has_think}")
                print(f"  –ï—Å—Ç—å <answer>: {has_answer}")
                print(f"  –§–æ—Ä–º–∞—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π: {format_ok}")
                print(f"  –°—Ç—Ä–æ–≥–∏–π —Ñ–æ—Ä–º–∞—Ç <answer>X.XXX</answer>: {strict_format_ok}")
                
                if format_ok:
                    format_correct += 1
                if strict_format_ok:
                    strict_format_correct += 1
                
                print("=" * 80)
                
                # –ü—Ä–æ–≥—Ä–µ—Å—Å
                if (i + 1) % 5 == 0 or (i + 1) == total:
                    print(f"  –°–ª–æ–∂–Ω–æ—Å—Ç—å {difficulty}: {i+1}/{total} –∑–∞–¥–∞—á...", end='\r')
            
            accuracy = correct / total if total > 0 else 0.0
            format_score = format_correct / total if total > 0 else 0.0
            strict_format_score = strict_format_correct / total if total > 0 else 0.0
            results[difficulty] = {
                "accuracy": accuracy,
                "format_score": format_score,
                "strict_format_score": strict_format_score
            }
            print(f"  –°–ª–æ–∂–Ω–æ—Å—Ç—å {difficulty}: {correct}/{total} = {accuracy:.1%} | –§–æ—Ä–º–∞—Ç: {format_correct}/{total} = {format_score:.1%} | –°—Ç—Ä–æ–≥–∏–π —Ñ–æ—Ä–º–∞—Ç: {strict_format_correct}/{total} = {strict_format_score:.1%}    ")
        
        # –û–±—â–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏
        avg_accuracy = sum(r["accuracy"] for r in results.values()) / len(results) if results else 0.0
        avg_format = sum(r["format_score"] for r in results.values()) / len(results) if results else 0.0
        avg_strict_format = sum(r["strict_format_score"] for r in results.values()) / len(results) if results else 0.0
        print(f"  üìä –°—Ä–µ–¥–Ω—è—è —Ç–æ—á–Ω–æ—Å—Ç—å: {avg_accuracy:.1%} | –°—Ä–µ–¥–Ω–∏–π —Ñ–æ—Ä–º–∞—Ç: {avg_format:.1%} | –°—Ä–µ–¥–Ω–∏–π —Å—Ç—Ä–æ–≥–∏–π —Ñ–æ—Ä–º–∞—Ç: {avg_strict_format:.1%}\n")
        
        return results
    
    def run_evaluation(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω—É—é –æ—Ü–µ–Ω–∫—É –≤—Å–µ—Ö —Ç—Ä–µ—Ö –º–µ—Ç–æ–¥–æ–≤."""
        print("================================================")
        print("                –û–¶–ï–ù–ö–ê –ú–û–î–ï–õ–ï–ô DC CIRCUIT ANALYSIS")
        print("================================================")
        
        # üîç –û–¢–õ–ê–î–û–ß–ù–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø
        print(f"\nüîß –û–¢–õ–ê–î–û–ß–ù–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø:")
        print(f"üìä –û–±—Ä–∞–∑—Ü–æ–≤ –Ω–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç—å: {self.samples_per_difficulty}")
        print(f"üéØ –°–ª–æ–∂–Ω–æ—Å—Ç–∏: {self.circuit_config.difficulties}")
        print(f"üå°Ô∏è –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞: {self.DEFAULT_TEMPERATURE}")
        print(f"üíæ GPU –ø–∞–º—è—Ç—å: {self.DEFAULT_GPU_MEMORY_UTILIZATION}")
        print(f"üìè –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞: {self.training_config.max_completion_length}")
        print("=" * 80)
        
        # 1. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        test_data = self.generate_test_data()
        
        # 2. –ó–∞–≥—Ä—É–∑–∫–∞ baseline –º–æ–¥–µ–ª–∏
        baseline_llm, baseline_sampling_params = self.load_model(
            self.baseline_model_name, 
            is_trained=False
        )
        
        # 3. Zero-shot –æ—Ü–µ–Ω–∫–∞ (–±–µ–∑ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞)
        print("-"*70)
        zero_shot_results = self.evaluate_model_on_data(
            baseline_llm,
            baseline_sampling_params,
            test_data,
            "Zero-shot (no system prompt)",
            use_system_prompt=False
        )
        
        # 4. Prompt Engineering –æ—Ü–µ–Ω–∫–∞ (—Å —Å–∏—Å—Ç–µ–º–Ω—ã–º –ø—Ä–æ–º–ø—Ç–æ–º)
        print("-"*70)
        prompt_eng_results = self.evaluate_model_on_data(
            baseline_llm,
            baseline_sampling_params,
            test_data,
            "Prompt Engineering (with system prompt)",
            use_system_prompt=True
        )
        
        # –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏
        del baseline_llm, baseline_sampling_params
        torch.cuda.empty_cache()
        
        # 5. GRPO Trained –æ—Ü–µ–Ω–∫–∞ (–µ—Å–ª–∏ –º–æ–¥–µ–ª—å —Å—É—â–µ—Å—Ç–≤—É–µ—Ç)
        print("-"*70)
        grpo_results = {}
        if os.path.exists(self.trained_model_path):
            trained_llm, trained_sampling_params = self.load_model(
                self.trained_model_path,
                is_trained=True
            )
            
            grpo_results = self.evaluate_model_on_data(
                trained_llm,
                trained_sampling_params,
                test_data,
                "GRPO Trained (with LoRA)",
                use_system_prompt=True
            )
            
            del trained_llm, trained_sampling_params
            torch.cuda.empty_cache()
        else:
            print(f"‚ö†Ô∏è  –û–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {self.trained_model_path}")
            print(f"   –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ—Ü–µ–Ω–∫—É GRPO Trained\n")
            grpo_results = {1: {"accuracy": 0.0, "format_score": 0.0, "strict_format_score": 0.0}, 
                           2: {"accuracy": 0.0, "format_score": 0.0, "strict_format_score": 0.0}}
        
        # 6. –í—ã–≤–æ–¥ –∏—Ç–æ–≥–æ–≤—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        self.print_summary(zero_shot_results, prompt_eng_results, grpo_results)
        
        return {
            "zero_shot": zero_shot_results,
            "prompt_engineering": prompt_eng_results,
            "grpo_trained": grpo_results
        }
    
    def print_summary(
        self,
        zero_shot: Dict[int, Dict[str, float]],
        prompt_eng: Dict[int, Dict[str, float]],
        grpo: Dict[int, Dict[str, float]]
    ):
        """–í—ã–≤–æ–¥–∏—Ç –∏—Ç–æ–≥–æ–≤—É—é —Ç–∞–±–ª–∏—Ü—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å –∫—Ä–∞—Å–∏–≤–æ–π –¥–∏–∞–≥—Ä–∞–º–º–æ–π.
        
        Args:
            zero_shot: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã Zero-shot
            prompt_eng: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã Prompt Engineering
            grpo: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã GRPO
        """
        print("="*80)
        print(" üìä –ò–¢–û–ì–û–í–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´")
        print("="*80)
        print()
        
        # –¢–∞–±–ª–∏—Ü–∞ —Ç–æ—á–Ω–æ—Å—Ç–∏
        print("üéØ –¢–û–ß–ù–û–°–¢–¨ –û–¢–í–ï–¢–û–í:")
        print("| –ú–µ—Ç–æ–¥                  | –°–ª–æ–∂–Ω–æ—Å—Ç—å 1 | –°–ª–æ–∂–Ω–æ—Å—Ç—å 2 | –°—Ä–µ–¥–Ω–µ–µ |")
        print("|------------------------|-------------|-------------|---------|")
        
        # Zero-shot
        avg_zero_acc = sum(zero_shot[d]["accuracy"] for d in zero_shot) / len(zero_shot) if zero_shot else 0.0
        print(f"| Zero-shot              | {zero_shot.get(1, {}).get('accuracy', 0.0):>10.1%} | "
              f"{zero_shot.get(2, {}).get('accuracy', 0.0):>10.1%} | {avg_zero_acc:>6.1%} |")
        
        # Prompt Engineering
        avg_pe_acc = sum(prompt_eng[d]["accuracy"] for d in prompt_eng) / len(prompt_eng) if prompt_eng else 0.0
        print(f"| Prompt Engineering     | {prompt_eng.get(1, {}).get('accuracy', 0.0):>10.1%} | "
              f"{prompt_eng.get(2, {}).get('accuracy', 0.0):>10.1%} | {avg_pe_acc:>6.1%} |")
        
        # GRPO Trained
        avg_grpo_acc = sum(grpo[d]["accuracy"] for d in grpo) / len(grpo) if grpo else 0.0
        print(f"| GRPO Trained           | {grpo.get(1, {}).get('accuracy', 0.0):>10.1%} | "
              f"{grpo.get(2, {}).get('accuracy', 0.0):>10.1%} | {avg_grpo_acc:>6.1%} |")
        
        print()
        
        # –¢–∞–±–ª–∏—Ü–∞ —Ñ–æ—Ä–º–∞—Ç–∞
        print("üìù –ü–†–ê–í–ò–õ–¨–ù–´–ô –§–û–†–ú–ê–¢ –û–¢–í–ï–¢–û–í:")
        print("| –ú–µ—Ç–æ–¥                  | –°–ª–æ–∂–Ω–æ—Å—Ç—å 1 | –°–ª–æ–∂–Ω–æ—Å—Ç—å 2 | –°—Ä–µ–¥–Ω–µ–µ |")
        print("|------------------------|-------------|-------------|---------|")
        
        # Zero-shot format
        avg_zero_fmt = sum(zero_shot[d]["format_score"] for d in zero_shot) / len(zero_shot) if zero_shot else 0.0
        print(f"| Zero-shot              | {zero_shot.get(1, {}).get('format_score', 0.0):>10.1%} | "
              f"{zero_shot.get(2, {}).get('format_score', 0.0):>10.1%} | {avg_zero_fmt:>6.1%} |")
        
        # Prompt Engineering format
        avg_pe_fmt = sum(prompt_eng[d]["format_score"] for d in prompt_eng) / len(prompt_eng) if prompt_eng else 0.0
        print(f"| Prompt Engineering     | {prompt_eng.get(1, {}).get('format_score', 0.0):>10.1%} | "
              f"{prompt_eng.get(2, {}).get('format_score', 0.0):>10.1%} | {avg_pe_fmt:>6.1%} |")
        
        # GRPO Trained format
        avg_grpo_fmt = sum(grpo[d]["format_score"] for d in grpo) / len(grpo) if grpo else 0.0
        print(f"| GRPO Trained           | {grpo.get(1, {}).get('format_score', 0.0):>10.1%} | "
              f"{grpo.get(2, {}).get('format_score', 0.0):>10.1%} | {avg_grpo_fmt:>6.1%} |")
        
        print()
        # –¢–∞–±–ª–∏—Ü–∞ —Å—Ç—Ä–æ–≥–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞
        print("üîí –°–¢–†–û–ì–ò–ô –§–û–†–ú–ê–¢ <answer>X.XXX</answer>:")
        print("| –ú–µ—Ç–æ–¥                  | –°–ª–æ–∂–Ω–æ—Å—Ç—å 1 | –°–ª–æ–∂–Ω–æ—Å—Ç—å 2 | –°—Ä–µ–¥–Ω–µ–µ |")
        print("|------------------------|-------------|-------------|---------|")
        avg_zero_strict = sum(zero_shot[d]["strict_format_score"] for d in zero_shot) / len(zero_shot) if zero_shot else 0.0
        print(f"| Zero-shot              | {zero_shot.get(1, {}).get('strict_format_score', 0.0):>10.1%} | "
              f"{zero_shot.get(2, {}).get('strict_format_score', 0.0):>10.1%} | {avg_zero_strict:>6.1%} |")
        avg_pe_strict = sum(prompt_eng[d]["strict_format_score"] for d in prompt_eng) / len(prompt_eng) if prompt_eng else 0.0
        print(f"| Prompt Engineering     | {prompt_eng.get(1, {}).get('strict_format_score', 0.0):>10.1%} | "
              f"{prompt_eng.get(2, {}).get('strict_format_score', 0.0):>10.1%} | {avg_pe_strict:>6.1%} |")
        avg_grpo_strict = sum(grpo[d]["strict_format_score"] for d in grpo) / len(grpo) if grpo else 0.0
        print(f"| GRPO Trained           | {grpo.get(1, {}).get('strict_format_score', 0.0):>10.1%} | "
              f"{grpo.get(2, {}).get('strict_format_score', 0.0):>10.1%} | {avg_grpo_strict:>6.1%} |")
        print()
        
        # –ö—Ä–∞—Å–∏–≤–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞
        self.print_visual_chart(avg_zero_acc, avg_pe_acc, avg_grpo_acc, avg_zero_fmt, avg_pe_fmt, avg_grpo_fmt)
    
    def print_visual_chart(self, acc_zero, acc_pe, acc_grpo, fmt_zero, fmt_pe, fmt_grpo):
        """–°–æ–∑–¥–∞–µ—Ç –∫—Ä–∞—Å–∏–≤—É—é ASCII –¥–∏–∞–≥—Ä–∞–º–º—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤."""
        print("üìà –í–ò–ó–£–ê–õ–¨–ù–ê–Ø –î–ò–ê–ì–†–ê–ú–ú–ê –†–ï–ó–£–õ–¨–¢–ê–¢–û–í:")
        print("="*60)
        print()
        
        # –î–∏–∞–≥—Ä–∞–º–º–∞ —Ç–æ—á–Ω–æ—Å—Ç–∏
        print("üéØ –¢–û–ß–ù–û–°–¢–¨ –û–¢–í–ï–¢–û–í:")
        self._print_bar_chart([
            ("Zero-shot", acc_zero),
            ("Prompt Eng", acc_pe), 
            ("GRPO Trained", acc_grpo)
        ])
        
        print()
        
        # –î–∏–∞–≥—Ä–∞–º–º–∞ —Ñ–æ—Ä–º–∞—Ç–∞
        print("üìù –ü–†–ê–í–ò–õ–¨–ù–´–ô –§–û–†–ú–ê–¢:")
        self._print_bar_chart([
            ("Zero-shot", fmt_zero),
            ("Prompt Eng", fmt_pe),
            ("GRPO Trained", fmt_grpo)
        ])
        
        print()
        # –î–∏–∞–≥—Ä–∞–º–º–∞ —Å—Ç—Ä–æ–≥–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞
        print("üîí –°–¢–†–û–ì–ò–ô –§–û–†–ú–ê–¢:")

    
    def _print_bar_chart(self, data):
        """–°–æ–∑–¥–∞–µ—Ç ASCII bar chart."""
        max_val = max(item[1] for item in data) if data else 0
        if max_val == 0:
            max_val = 1
        
        for name, value in data:
            bar_length = int(value * 30 / max_val) if max_val > 0 else 0
            bar = "‚ñà" * bar_length + "‚ñë" * (30 - bar_length)
            print(f"  {name:<12} ‚îÇ{bar}‚îÇ {value:.1%}")
    


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è."""
    evaluator = Evaluator(
        baseline_model="unsloth/Qwen2.5-0.5B",
        trained_model_path="./dc_circuit_model_rl",
        samples_per_difficulty=5
    )
    
    results = evaluator.run_evaluation()
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Ñ–∞–π–ª
    import json
    with open("evaluation_results.json", "w") as f:
        json.dump(results, f, indent=2)
    print("üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ evaluation_results.json")


if __name__ == "__main__":
    main()