import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from typing import List, Dict
import re
import mlx.core as mx
import mlx.nn as nn
from mlx_lm import load, generate
import matplotlib.pyplot as plt
import numpy as np

from base.data import Data
from dc_circuit.game import DCCircuitGame
from config import CircuitConfig, VerifierConfig, TrainingConfig
from base.utils import get_system_prompt

# –ì–ª–æ–±–∞–ª—å–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è –ø–∞–ø–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
results_dir = "results"



class Evaluator:
    """–û—Ü–µ–Ω—â–∏–∫ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π (MLX –≤–µ—Ä—Å–∏—è)."""


    def __init__(
        self,
        baseline_model: str = "unsloth/Qwen2.5-1.5B-instruct",  # –ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª—é–±—É—é HF –º–æ–¥–µ–ª—å!
        trained_model_path: str = "./dc_circuit_model_rl",
        samples_per_difficulty: int = 5
    ):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ—Ü–µ–Ω—â–∏–∫–∞.

        Args:
            baseline_model: –ù–∞–∑–≤–∞–Ω–∏–µ –ª—é–±–æ–π HF –º–æ–¥–µ–ª–∏ (mlx-lm –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)
            trained_model_path: –ü—É—Ç—å –∫ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
            samples_per_difficulty: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–¥–∞—á –Ω–∞ —É—Ä–æ–≤–µ–Ω—å —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
        """
        self.baseline_model_name = baseline_model
        self.trained_model_path = trained_model_path
        self.samples_per_difficulty = samples_per_difficulty

        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        self.circuit_config = CircuitConfig()
        self.verifier_config = VerifierConfig()
        self.training_config = TrainingConfig()

        # Game –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏ –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏
        self.game = DCCircuitGame(self.circuit_config, self.verifier_config)

    def _has_strict_answer_format(self, response: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—Ç—Ä–æ–≥–∏–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ –≤ <answer>: —Ä–æ–≤–Ω–æ —á–∏—Å–ª–æ —Å 3 –∑–Ω–∞–∫–∞–º–∏.

        –£—Å–ª–æ–≤–∏—è:
        - –í —Ç–µ–∫—Å—Ç–µ –µ—Å—Ç—å —Ç–µ–≥–∏ <answer>...</answer>
        - –í–Ω—É—Ç—Ä–∏ —Ä–æ–≤–Ω–æ –æ–¥–Ω–æ —á–∏—Å–ª–æ —Ñ–æ—Ä–º–∞—Ç–∞ X.XXX (3 –¥–µ—Å—è—Ç–∏—á–Ω—ã—Ö –∑–Ω–∞–∫–∞)
        - –ù–µ—Ç –µ–¥–∏–Ω–∏—Ü –∏–∑–º–µ—Ä–µ–Ω–∏—è –∏ –ª–∏—à–Ω–µ–≥–æ —Ç–µ–∫—Å—Ç–∞
        """
        if not response:
            return False
        # –ù–∞–π—Ç–∏ –ø–æ—Å–ª–µ–¥–Ω–∏–π <answer>...</answer>
        tag_matches = re.findall(r"<answer>([\s\S]*?)</answer>", response, flags=re.IGNORECASE)
        if not tag_matches:
            return False
        content = tag_matches[-1].strip()
        # –î–æ–ª–∂–Ω–æ –±—ã—Ç—å —Å—Ç—Ä–æ–≥–æ —á–∏—Å–ª–æ —Å 3 –¥–µ—Å—è—Ç–∏—á–Ω—ã–º–∏, –±–µ–∑ –µ–¥–∏–Ω–∏—Ü –∏ —Ç–µ–∫—Å—Ç–∞
        return bool(re.fullmatch(r"[-+]?\d+\.\d{3}", content))

    def generate_test_data(self) -> Dict[int, List[Data]]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤—Å–µ—Ö —É—Ä–æ–≤–Ω–µ–π —Å–ª–æ–∂–Ω–æ—Å—Ç–∏.

        Returns:
            –°–ª–æ–≤–∞—Ä—å {difficulty: list_of_data}
        """
        print("\nüìù –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
        test_data = {}

        for difficulty in [1, 2, 5, 6]:
            print(f"  –°–ª–æ–∂–Ω–æ—Å—Ç—å {difficulty}: –≥–µ–Ω–µ—Ä–∞—Ü–∏—è {self.samples_per_difficulty} –∑–∞–¥–∞—á...")
            data_list = self.game.generate(
                num_of_questions=self.samples_per_difficulty,
                difficulty=difficulty
            )
            test_data[difficulty] = data_list
            print(f"    ‚úì –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(data_list)} –∑–∞–¥–∞—á")

        total = sum(len(data) for data in test_data.values())
        print(f"  –í—Å–µ–≥–æ —Ç–µ—Å—Ç–æ–≤—ã—Ö –∑–∞–¥–∞—á: {total}\n")

        return test_data

    def load_model(self, model_path: str, is_trained: bool = False):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å —á–µ—Ä–µ–∑ MLX –∏–ª–∏ transformers (–¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å LoRA).

        Args:
            model_path: –ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏ –∏–ª–∏ Hugging Face ID (–ª—é–±–∞—è HF –º–æ–¥–µ–ª—å)
            is_trained: True –µ—Å–ª–∏ —ç—Ç–æ –æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å —Å LoRA

        Returns:
            (model, tokenizer) - –º–æ–¥–µ–ª—å –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä
        """
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –º–æ–¥–µ–ª–∏: Hugging Face –∏–ª–∏ –ª–æ–∫–∞–ª—å–Ω–∞—è
        is_huggingface = "/" in model_path and not model_path.startswith("./") and not model_path.startswith("../") and not model_path.startswith("/")

        if is_huggingface:
            # Hugging Face –º–æ–¥–µ–ª—å - –∏—Å–ø–æ–ª—å–∑—É–µ–º MLX
            print(f"üöÄ –ó–∞–≥—Ä—É–∑–∫–∞ HF –º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ MLX: {model_path}")
            try:
                model, tokenizer = load(model_path)
                print("  ‚úì –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —á–µ—Ä–µ–∑ MLX\n")
            except Exception as e:
                print(f"‚ö†Ô∏è  MLX –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω ({e}), –∏—Å–ø–æ–ª—å–∑—É–µ–º transformers")
                from transformers import AutoModelForCausalLM, AutoTokenizer
                model = AutoModelForCausalLM.from_pretrained(
                    model_path,
                    torch_dtype="auto",
                    device_map="auto",
                    trust_remote_code=True
                )
                tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)
                print("  ‚úì –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —á–µ—Ä–µ–∑ transformers\n")
        else:
            # –õ–æ–∫–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å (LoRA) - –∏—Å–ø–æ–ª—å–∑—É–µ–º transformers –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
            print(f"üì¶ –ó–∞–≥—Ä—É–∑–∫–∞ –ª–æ–∫–∞–ª—å–Ω–æ–π LoRA –º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ transformers: {model_path}")

            from transformers import AutoModelForCausalLM, AutoTokenizer

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –ø—É—Ç–∏
            if not os.path.exists(model_path):
                possible_paths = [
                    model_path,
                    f"./{model_path}",
                    f"../{model_path}",
                    os.path.join(os.getcwd(), model_path),
                    os.path.join(os.path.dirname(os.getcwd()), model_path)
                ]
                for path in possible_paths:
                    if os.path.exists(path):
                        model_path = path
                        break
                else:
                    raise FileNotFoundError(f"–ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –ø–æ –ø—É—Ç—è–º: {possible_paths}")

            # –ó–∞–≥—Ä—É–∂–∞–µ–º –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å + LoRA –∞–¥–∞–ø—Ç–µ—Ä
            try:
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å –∏–∑ –∞–¥–∞–ø—Ç–µ—Ä–∞
                import json
                with open(os.path.join(model_path, "adapter_config.json"), "r") as f:
                    adapter_config = json.load(f)
                base_model_name = adapter_config.get("base_model_name_or_path", "unsloth/Qwen2.5-1.5B-instruct")

                print(f"  –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å: {base_model_name}")
                print(f"  LoRA –∞–¥–∞–ø—Ç–µ—Ä: {model_path}")

                # –ó–∞–≥—Ä—É–∂–∞–µ–º –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å
                model = AutoModelForCausalLM.from_pretrained(
                    base_model_name,
                    torch_dtype="auto",
                    device_map="auto",
                    trust_remote_code=True
                )

                # –ó–∞–≥—Ä—É–∂–∞–µ–º LoRA –∞–¥–∞–ø—Ç–µ—Ä
                from peft import PeftModel
                model = PeftModel.from_pretrained(model, model_path)

                tokenizer = AutoTokenizer.from_pretrained(base_model_name, trust_remote_code=True)
                print("  ‚úì LoRA –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —á–µ—Ä–µ–∑ transformers\n")

            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ LoRA –º–æ–¥–µ–ª–∏: {e}")
                raise

        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º chat template –¥–ª—è Qwen (–µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç)
        if tokenizer.chat_template is None:
            tokenizer.chat_template = """{% for message in messages %}
{% if message['role'] == 'system' %}
<|im_start|>system
{{ message['content'] }}<|im_end|>
{% elif message['role'] == 'user' %}
<|im_start|>user
{{ message['content'] }}<|im_end|>
{% elif message['role'] == 'assistant' %}
<|im_start|>assistant
{{ message['content'] }}<|im_end|>
{% endif %}
{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n' }}{% endif %}"""

        return model, tokenizer

    def generate_answer(
        self,
        model,
        tokenizer,
        question: str,
        use_mlx: bool = True
    ) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ MLX –∏–ª–∏ transformers.

        Args:
            model: –ú–æ–¥–µ–ª—å (MLX –∏–ª–∏ transformers)
            tokenizer: –¢–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä
            question: –í–æ–ø—Ä–æ—Å
            use_mlx: True –¥–ª—è MLX –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏, False –¥–ª—è transformers

        Returns:
            –û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏
        """
        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç
        messages = []

        # –í—Å–µ–≥–¥–∞ –¥–æ–±–∞–≤–ª—è–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç RL —Å—Ä–µ–¥—ã
        messages.append({"role": "system", "content": get_system_prompt()})

        # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π –≤–æ–ø—Ä–æ—Å (—É–∂–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –æ–ø–∏—Å–∞–Ω–∏–µ —Ü–µ–ø–∏ –∏–∑ —Å—Ä–µ–¥—ã)
        messages.append({"role": "user", "content": question})

        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è MLX
        prompt_parts = []
        for message in messages:
            if message["role"] == "system":
                prompt_parts.append(f"<|im_start|>system\n{message['content']}<|im_end|>")
            elif message["role"] == "user":
                prompt_parts.append(f"<|im_start|>user\n{message['content']}<|im_end|>")
            elif message["role"] == "assistant":
                prompt_parts.append(f"<|im_start|>assistant\n{message['content']}<|im_end|>")

        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–∞—á–∞–ª–æ –æ—Ç–≤–µ—Ç–∞ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –≤–æ–ø—Ä–æ—Å–∞
        prompt_parts.append("<|im_start|>assistant\n")
        prompt = "\n".join(prompt_parts)

        # üîç –û–¢–õ–ê–î–û–ß–ù–´–ô –í–´–í–û–î –ì–ï–ù–ï–†–ê–¶–ò–ò
        print(f"\nüîß –û–¢–õ–ê–î–ö–ê –ì–ï–ù–ï–†–ê–¶–ò–ò:")
        print(f"üìù –ü–†–û–ú–ü–¢ (–ø–µ—Ä–≤—ã–µ 200 —Å–∏–º–≤–æ–ª–æ–≤): {prompt[:200]}...")

        if use_mlx:
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç —á–µ—Ä–µ–∑ MLX
            response = generate(
                model,
                tokenizer,
                prompt=prompt,
                max_tokens=self.training_config.max_completion_length,
                verbose=False
            )
        else:
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç —á–µ—Ä–µ–∑ transformers (–¥–ª—è LoRA –º–æ–¥–µ–ª–µ–π)
            import torch
            inputs = tokenizer(prompt, return_tensors="pt")

            # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏
            if hasattr(model, 'device'):
                inputs = inputs.to(model.device)

            with torch.no_grad():
                outputs = model.generate(
                    **inputs,
                    max_new_tokens=self.training_config.max_completion_length,
                    do_sample=True,
                    pad_token_id=tokenizer.pad_token_id,
                    eos_token_id=tokenizer.eos_token_id
                )

            response = tokenizer.decode(outputs[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True)

        print(f"ü§ñ –ü–û–õ–ù–´–ô –û–¢–í–ï–¢ –ú–û–î–ï–õ–ò:")
        print(f"{response}")
        print(f"üìè –î–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞: {len(response)} —Å–∏–º–≤–æ–ª–æ–≤")


        return response

    def evaluate_model_on_data(
        self,
        model,
        tokenizer,
        test_data: Dict[int, List[Data]],
        method_name: str,
        use_mlx: bool = True
    ) -> Dict[int, Dict[str, float]]:
        """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç –º–æ–¥–µ–ª—å –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö.

        Args:
            model: –ú–æ–¥–µ–ª—å (MLX –∏–ª–∏ transformers)
            tokenizer: –¢–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä
            test_data: –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
            method_name: –ù–∞–∑–≤–∞–Ω–∏–µ –º–µ—Ç–æ–¥–∞ –¥–ª—è –≤—ã–≤–æ–¥–∞
            use_mlx: True –¥–ª—è MLX –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏, False –¥–ª—è transformers

        Returns:
            –°–ª–æ–≤–∞—Ä—å {difficulty: {"accuracy": float, "format_score": float, "strict_format_score": float}}
        """
        print(f"üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ: {method_name}")

        # üîç –û–¢–õ–ê–î–û–ß–ù–´–ô –í–´–í–û–î –°–ò–°–¢–ï–ú–ù–û–ì–û –ü–†–û–ú–ü–¢–ê
        from base.utils import get_system_prompt
        system_prompt = get_system_prompt()
        print(f"\nüìã –°–ò–°–¢–ï–ú–ù–´–ô –ü–†–û–ú–ü–¢ RL –°–†–ï–î–´:")
        print("=" * 80)
        print(f"{system_prompt}")
        print("=" * 80)

        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –∑–∞–¥–∞—á–∏ –ø–æ —Ç–∏–ø–∞–º —Ü–µ–ø–µ–π
        circuit_type_results = {"series": {}, "parallel": {}}

        results = {}

        for difficulty, data_list in sorted(test_data.items()):
            # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Ç–∏–ø–∞–º —Ü–µ–ø–µ–π
            series_correct = 0
            series_format_correct = 0
            series_strict_format_correct = 0
            series_total = 0

            parallel_correct = 0
            parallel_format_correct = 0
            parallel_strict_format_correct = 0
            parallel_total = 0

            for i, data in enumerate(data_list):
                # –ü–æ–ª—É—á–∞–µ–º —Ç–∏–ø —Ü–µ–ø–∏ –∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
                circuit_type = getattr(data, 'metadata', {}).get('circuit_type', 'unknown')
                question_type = getattr(data, 'metadata', {}).get('question_type', 'unknown')
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
                response = self.generate_answer(
                    model, tokenizer, data.question, use_mlx
                )

    
                print("=" * 80)
                print(f"üìã –ü–û–õ–ù–ê–Ø –ó–ê–î–ê–ß–ê:")
                print(f"{data.question}")
                print(f"\n‚úÖ –û–ñ–ò–î–ê–ï–ú–´–ô –û–¢–í–ï–¢: {data.answer}")
                print(f"\nü§ñ –û–¢–í–ï–¢ –ú–û–î–ï–õ–ò:")
                print(f"{response}")

                # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Ç–≤–µ—Ç –∏–∑ –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ–ª–∏
                from base.utils import extract_answer
                extracted_answer = extract_answer(response)
                print(f"\nüîç –ò–ó–í–õ–ï–ß–ï–ù–ù–´–ô –û–¢–í–ï–¢: '{extracted_answer}'")

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å
                accuracy_score = self.game.verifier.get_accuracy_score(data, response)
                print(f"\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢ –í–ï–†–ò–§–ò–ö–ê–¶–ò–ò:")

                print(f"  Accuracy Score: {accuracy_score:.3f}")

                # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ has_think, has_answer, strict_format_ok –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã
                has_think = "<think>" in response.lower()
                has_answer = "<answer>" in response.lower()
                strict_format_ok = self._has_strict_answer_format(response)

                # –°—É–º–º–∏—Ä—É–µ–º accuracy score –ø–æ —Ç–∏–ø–∞–º —Ü–µ–ø–µ–π
                if circuit_type == "series":
                    series_correct += accuracy_score
                    series_total += 1
                    # –¢–µ–ø–µ—Ä—å format_ok —É—á–∏—Ç—ã–≤–∞–µ—Ç –∏ —Ç–µ–≥–∏ –ò —Å—Ç—Ä–æ–≥–∏–π —Ñ–æ—Ä–º–∞—Ç
                    if has_think and has_answer and strict_format_ok:
                        series_format_correct += 1
                    if strict_format_ok:
                        series_strict_format_correct += 1
                elif circuit_type == "parallel":
                    parallel_correct += accuracy_score
                    parallel_total += 1
                    # –¢–µ–ø–µ—Ä—å format_ok —É—á–∏—Ç—ã–≤–∞–µ—Ç –∏ —Ç–µ–≥–∏ –ò —Å—Ç—Ä–æ–≥–∏–π —Ñ–æ—Ä–º–∞—Ç
                    if has_think and has_answer and strict_format_ok:
                        parallel_format_correct += 1
                    if strict_format_ok:
                        parallel_strict_format_correct += 1

                print("=" * 80)

                # –ü—Ä–æ–≥—Ä–µ—Å—Å
                if (i + 1) % 5 == 0 or (i + 1) == len(data_list):
                    print(f"  –°–ª–æ–∂–Ω–æ—Å—Ç—å {difficulty}: {i+1}/{len(data_list)} –∑–∞–¥–∞—á...", end='\r')

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–∏–ø–∞ —Ü–µ–ø–∏
            if series_total > 0:
                series_accuracy = round(series_correct) / series_total
                series_format_score = series_format_correct / series_total
                series_strict_format_score = series_strict_format_correct / series_total
                circuit_type_results["series"][difficulty] = {
                    "accuracy": series_accuracy,
                    "format_score": series_format_score,
                    "strict_format_score": series_strict_format_score,
                    "total_tasks": series_total
                }
                print(f"  –°–ª–æ–∂–Ω–æ—Å—Ç—å {difficulty} (Series): {round(series_correct)}/{series_total} = {series_accuracy:.1%} | –§–æ—Ä–º–∞—Ç (—Å—Ç—Ä–æ–≥–∏–π): {series_format_correct}/{series_total} = {series_format_score:.1%}")

            if parallel_total > 0:
                parallel_accuracy = round(parallel_correct) / parallel_total
                parallel_format_score = parallel_format_correct / parallel_total
                parallel_strict_format_score = parallel_strict_format_correct / parallel_total
                circuit_type_results["parallel"][difficulty] = {
                    "accuracy": parallel_accuracy,
                    "format_score": parallel_format_score,
                    "strict_format_score": parallel_strict_format_score,
                    "total_tasks": parallel_total
                }
                print(f"  –°–ª–æ–∂–Ω–æ—Å—Ç—å {difficulty} (Parallel): {round(parallel_correct)}/{parallel_total} = {parallel_accuracy:.1%} | –§–æ—Ä–º–∞—Ç (—Å—Ç—Ä–æ–≥–∏–π): {parallel_format_correct}/{parallel_total} = {parallel_format_score:.1%}")

        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ —Ç–∏–ø–∞–º —Ü–µ–ø–µ–π
        return circuit_type_results

    def run_evaluation(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω—É—é –æ—Ü–µ–Ω–∫—É –≤—Å–µ—Ö —Ç—Ä–µ—Ö –º–µ—Ç–æ–¥–æ–≤."""
        print("================================================")
        print("                –û–¶–ï–ù–ö–ê –ú–û–î–ï–õ–ï–ô DC CIRCUIT ANALYSIS (MLX)")
        print("================================================")

        # üîç –û–¢–õ–ê–î–û–ß–ù–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø
        print(f"\nüîß –û–¢–õ–ê–î–û–ß–ù–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø:")
        print(f"üìä –û–±—Ä–∞–∑—Ü–æ–≤ –Ω–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç—å: {self.samples_per_difficulty}")
        print(f"üéØ –°–ª–æ–∂–Ω–æ—Å—Ç–∏: {self.circuit_config.difficulties}")
        print(f"üìè –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞: {self.training_config.max_completion_length}")
        print("=" * 80)

        # 1. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        test_data = self.generate_test_data()

        # 2. –ó–∞–≥—Ä—É–∑–∫–∞ baseline –º–æ–¥–µ–ª–∏
        baseline_model, baseline_tokenizer = self.load_model(
            self.baseline_model_name,
            is_trained=False
        )

        # 3. Baseline Model –æ—Ü–µ–Ω–∫–∞ (—Å —Å–∏—Å—Ç–µ–º–Ω—ã–º –ø—Ä–æ–º–ø—Ç–æ–º RL —Å—Ä–µ–¥—ã)
        print("-"*70)
        baseline_results = self.evaluate_model_on_data(
            baseline_model,
            baseline_tokenizer,
            test_data,
            "Baseline Model (with RL system prompt)",
            use_mlx=True  # HF –º–æ–¥–µ–ª—å —á–µ—Ä–µ–∑ MLX
        )

        # –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏
        del baseline_model, baseline_tokenizer

        # 5. GRPO Trained –æ—Ü–µ–Ω–∫–∞ (–µ—Å–ª–∏ –º–æ–¥–µ–ª—å —Å—É—â–µ—Å—Ç–≤—É–µ—Ç)
        print("-"*70)
        grpo_results = {"series": {}, "parallel": {}}
        if os.path.exists(self.trained_model_path):
            trained_model, trained_tokenizer = self.load_model(
                self.trained_model_path,
                is_trained=True
            )

            grpo_results = self.evaluate_model_on_data(
                trained_model,
                trained_tokenizer,
                test_data,
                "GRPO Trained (with LoRA)",
                use_mlx=False  # LoRA –º–æ–¥–µ–ª—å —á–µ—Ä–µ–∑ transformers
            )

            del trained_model, trained_tokenizer
        else:
            print(f"‚ö†Ô∏è  –û–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {self.trained_model_path}")
            print(f"   –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ—Ü–µ–Ω–∫—É GRPO Trained\n")
            # –°–æ–∑–¥–∞–µ–º –ø—É—Å—Ç—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–µ–π –º–æ–¥–µ–ª–∏
            grpo_results = {"series": {}, "parallel": {}}

        # 6. –í—ã–≤–æ–¥ –∏—Ç–æ–≥–æ–≤—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ —Ç–∏–ø–∞–º —Ü–µ–ø–µ–π
        self.print_summary(baseline_results, grpo_results)

        return {
            "baseline_model": baseline_results,
            "grpo_trained": grpo_results
        }

    def print_summary(
        self,
        baseline: Dict[str, Dict[int, Dict[str, float]]],
        grpo: Dict[str, Dict[int, Dict[str, float]]]
    ):
        """–í—ã–≤–æ–¥–∏—Ç –∏—Ç–æ–≥–æ–≤—É—é —Ç–∞–±–ª–∏—Ü—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ —Ç–∏–ø–∞–º —Ü–µ–ø–µ–π —Å –∫—Ä–∞—Å–∏–≤–æ–π –¥–∏–∞–≥—Ä–∞–º–º–æ–π.

        Args:
            baseline: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã Baseline Model –ø–æ —Ç–∏–ø–∞–º —Ü–µ–ø–µ–π
            grpo: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã GRPO Trained –ø–æ —Ç–∏–ø–∞–º —Ü–µ–ø–µ–π
        """
        print("="*80)
        print(" üìä –ò–¢–û–ì–û–í–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ü–û –¢–ò–ü–ê–ú –¶–ï–ü–ï–ô")
        print("="*80)
        print()

        for circuit_type in ["series", "parallel"]:
            if not baseline.get(circuit_type) and not grpo.get(circuit_type):
                continue

            print(f"üîå –¢–ò–ü –¶–ï–ü–ò: {circuit_type.upper()}")
            print("-" * 60)

            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –¥–ª—è —ç—Ç–æ–≥–æ —Ç–∏–ø–∞ —Ü–µ–ø–∏
            all_difficulties = set()
            if circuit_type in baseline:
                all_difficulties.update(baseline[circuit_type].keys())
            if circuit_type in grpo:
                all_difficulties.update(grpo[circuit_type].keys())
            difficulties = sorted(all_difficulties)

            if not difficulties:
                continue

            header = "| –ú–µ—Ç–æ–¥                  |" + "".join(f" –°–ª–æ–∂–Ω–æ—Å—Ç—å {d} |" for d in difficulties) + " –°—Ä–µ–¥–Ω–µ–µ |"
            separator = "|" + "-" * 24 + "|" + "".join("-" * 13 + "|" for _ in difficulties) + "-" * 9 + "|"

            print("üéØ –¢–û–ß–ù–û–°–¢–¨ –û–¢–í–ï–¢–û–í:")
            print(header)
            print(separator)

            # Baseline Model
            if circuit_type in baseline:
                baseline_values = [baseline[circuit_type].get(d, {}).get('accuracy', 0.0) for d in difficulties]
                avg_baseline_acc = sum(baseline_values) / len(baseline_values) if baseline_values else 0.0
                print(f"| Baseline Model         |" + "".join(f" {v:>10.1%} |" for v in baseline_values) + f" {avg_baseline_acc:>6.1%} |")
            else:
                print(f"| Baseline Model         |" + "".join("       0.0% |" for _ in difficulties) + "    0.0% |")

            # GRPO Trained
            if circuit_type in grpo:
                grpo_values = [grpo[circuit_type].get(d, {}).get('accuracy', 0.0) for d in difficulties]
                avg_grpo_acc = sum(grpo_values) / len(grpo_values) if grpo_values else 0.0
                print(f"| GRPO Trained           |" + "".join(f" {v:>10.1%} |" for v in grpo_values) + f" {avg_grpo_acc:>6.1%} |")
            else:
                print(f"| GRPO Trained           |" + "".join("       0.0% |" for _ in difficulties) + "    0.0% |")

            print()
            print(f"üìä –í—Å–µ–≥–æ –∑–∞–¥–∞—á –¥–ª—è {circuit_type}:")
            if circuit_type in baseline:
                total_baseline = sum(baseline[circuit_type].get(d, {}).get('total_tasks', 0) for d in difficulties)
                print(f"   Baseline: {total_baseline} –∑–∞–¥–∞—á")
            if circuit_type in grpo:
                total_grpo = sum(grpo[circuit_type].get(d, {}).get('total_tasks', 0) for d in difficulties)
                print(f"   GRPO: {total_grpo} –∑–∞–¥–∞—á")
            print("-" * 60)
            print()

        # –°–æ–∑–¥–∞–µ–º –¥–∏–∞–≥—Ä–∞–º–º—ã
        self.print_visual_chart(baseline, grpo)

    def print_visual_chart(self, baseline, grpo):
        """–°–æ–∑–¥–∞–µ—Ç –∫—Ä–∞—Å–∏–≤—ã–µ matplotlib –¥–∏–∞–≥—Ä–∞–º–º—ã –ø–æ —Ç–∏–ø–∞–º —Ü–µ–ø–µ–π."""
        # –°–æ–∑–¥–∞–µ–º –¥–∏–∞–≥—Ä–∞–º–º—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–∏–ø–∞ —Ü–µ–ø–∏ –æ—Ç–¥–µ–ª—å–Ω–æ
        for circuit_type in ["series", "parallel"]:
            baseline_circuit = baseline.get(circuit_type, {})
            grpo_circuit = grpo.get(circuit_type, {})

            if not baseline_circuit and not grpo_circuit:
                continue

            # –ü–æ–ª—É—á–∞–µ–º —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –¥–ª—è —ç—Ç–æ–≥–æ —Ç–∏–ø–∞ —Ü–µ–ø–∏
            all_difficulties = set(list(baseline_circuit.keys()) + list(grpo_circuit.keys()))
            difficulties = sorted(all_difficulties)

            if not difficulties:
                continue

            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –¥–∏–∞–≥—Ä–∞–º–º—ã
            methods = ["Baseline Model", "GRPO Trained"]
            accuracy_data = {
                'Baseline Model': [baseline_circuit.get(d, {}).get('accuracy', 0.0) * 100 for d in difficulties],
                'GRPO Trained': [grpo_circuit.get(d, {}).get('accuracy', 0.0) * 100 for d in difficulties]
            }

            format_data = {
                'Baseline Model': [baseline_circuit.get(d, {}).get('format_score', 0.0) * 100 for d in difficulties],
                'GRPO Trained': [grpo_circuit.get(d, {}).get('format_score', 0.0) * 100 for d in difficulties]
            }

            # –°–æ–∑–¥–∞–µ–º –¥–∏–∞–≥—Ä–∞–º–º—ã –¥–ª—è —ç—Ç–æ–≥–æ —Ç–∏–ø–∞ —Ü–µ–ø–∏
            colors = ['#FF6B6B', '#4ECDC4']

            # –î–∏–∞–≥—Ä–∞–º–º–∞: –¢–æ—á–Ω–æ—Å—Ç—å –ø–æ —Å–ª–æ–∂–Ω–æ—Å—Ç—è–º –¥–ª—è —Ç–∏–ø–∞ —Ü–µ–ø–∏
            plt.figure(figsize=(12, 8))
            x = np.arange(len(difficulties))
            width = 0.35

            for i, (method, values) in enumerate(accuracy_data.items()):
                offset = width * i
                bars = plt.bar(x + offset, values, width, label=method, color=colors[i], alpha=0.8)
                plt.bar_label(bars, fmt='%.1f%%', padding=3, fontsize=10)

            plt.ylabel('Accuracy (%)', fontsize=12)
            plt.title(f'DC Circuit Analysis - {circuit_type.title()} Circuits - Accuracy by Difficulty (MLX)', fontsize=14, fontweight='bold')
            plt.xticks(x + width/2, [f'Difficulty {d}' for d in difficulties])
            plt.legend(loc='upper left')
            plt.ylim(0, 100)
            plt.grid(True, alpha=0.3)
            plt.tight_layout()
            plt.savefig(f'{results_dir}/{circuit_type}_accuracy_by_difficulty.png', dpi=300, bbox_inches='tight')
            print(f"üìä –î–∏–∞–≥—Ä–∞–º–º–∞ {circuit_type} —Ç–æ—á–Ω–æ—Å—Ç—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {results_dir}/{circuit_type}_accuracy_by_difficulty.png")
            plt.close()


        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏: —Å—Ä–µ–¥–Ω–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏

        # –ì—Ä–∞—Ñ–∏–∫ 3: –°—Ä–µ–¥–Ω—è—è —Ç–æ—á–Ω–æ—Å—Ç—å –ø–æ –≤—Å–µ–º —É—Ä–æ–≤–Ω—è–º —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
        plt.figure(figsize=(10, 6))
        methods = ["Baseline Model", "GRPO Trained"]

        # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ –≤—Å–µ–º —Ç–∏–ø–∞–º —Ü–µ–ø–µ–π
        all_accuracy_data = {"Baseline Model": [], "GRPO Trained": []}
        all_format_data = {"Baseline Model": [], "GRPO Trained": []}

        for circuit_type in ["series", "parallel"]:
            baseline_circuit = baseline.get(circuit_type, {})
            grpo_circuit = grpo.get(circuit_type, {})

            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –¥–ª—è —ç—Ç–æ–≥–æ —Ç–∏–ø–∞ —Ü–µ–ø–∏
            all_difficulties = set(list(baseline_circuit.keys()) + list(grpo_circuit.keys()))
            difficulties = sorted(all_difficulties)

            if difficulties:
                # –î–æ–±–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ —Ç–æ—á–Ω–æ—Å—Ç–∏
                for method in methods:
                    if method == "Baseline Model":
                        circuit_data = baseline_circuit
                    else:
                        circuit_data = grpo_circuit

                    accuracy_values = [circuit_data.get(d, {}).get('accuracy', 0.0) * 100 for d in difficulties]
                    all_accuracy_data[method].extend(accuracy_values)

                    format_values = [circuit_data.get(d, {}).get('format_score', 0.0) * 100 for d in difficulties]
                    all_format_data[method].extend(format_values)

        # –°—Ä–µ–¥–Ω—è—è —Ç–æ—á–Ω–æ—Å—Ç—å
        avg_accuracy = [sum(all_accuracy_data[m]) / len(all_accuracy_data[m]) if all_accuracy_data[m] else 0 for m in methods]
        bars = plt.bar(methods, avg_accuracy, color=colors, alpha=0.8)
        plt.bar_label(bars, fmt='%.1f%%', padding=3, fontsize=12)

        plt.ylabel('Average Accuracy (%)', fontsize=12)
        plt.title('DC Circuit Analysis - Average Accuracy Across All Difficulties (MLX)', fontsize=14, fontweight='bold')
        plt.ylim(0, 100)
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.savefig(f'{results_dir}/overall_average_accuracy.png', dpi=300, bbox_inches='tight')
        print(f"üìä –ì—Ä–∞—Ñ–∏–∫ –æ–±—â–µ–π —Ç–æ—á–Ω–æ—Å—Ç–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {results_dir}/overall_average_accuracy.png")
        plt.close()

        # –ì—Ä–∞—Ñ–∏–∫ 4: –°—Ä–µ–¥–Ω–∏–π —Ñ–æ—Ä–º–∞—Ç (–æ–±—â–∏–π)
        plt.figure(figsize=(10, 6))
        avg_format = [sum(all_format_data[m]) / len(all_format_data[m]) if all_format_data[m] else 0 for m in methods]
        bars = plt.bar(methods, avg_format, color=colors, alpha=0.8)
        plt.bar_label(bars, fmt='%.1f%%', padding=3, fontsize=12)

        plt.ylabel('Average Format Score (%)', fontsize=12)
        plt.title('DC Circuit Analysis - Average Format Score Across All Tasks (MLX)', fontsize=14, fontweight='bold')
        plt.ylim(0, 100)
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.savefig(f'{results_dir}/overall_average_format.png', dpi=300, bbox_inches='tight')
        print(f"üìä –ì—Ä–∞—Ñ–∏–∫ –æ–±—â–µ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {results_dir}/overall_average_format.png")
        plt.close()

        print(f"üìä –í—Å–µ –¥–∏–∞–≥—Ä–∞–º–º—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ø–∞–ø–∫–µ {results_dir}/")


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è."""
    # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É results –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    if not os.path.exists(results_dir):
        os.makedirs(results_dir)

    evaluator = Evaluator(
        baseline_model="unsloth/Qwen2.5-1.5B-instruct",
        trained_model_path="/Users/stepprog/Downloads/content 2/dc_circuit_model_rl",
        samples_per_difficulty=5
    )

    results = evaluator.run_evaluation()

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Ñ–∞–π–ª
    import json
    results_file = f"{results_dir}/evaluation_results_mlx.json"
    with open(results_file, "w") as f:
        json.dump(results, f, indent=2)
    print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {results_file}")


if __name__ == "__main__":
    main()
