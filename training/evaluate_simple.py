"""C–∫—Ä–∏–ø—Ç –æ—Ü–µ–Ω–∫–∏ –º–æ–¥–µ–ª–µ–π –¥–ª—è DC Circuit Analysis.

–¢–µ—Å—Ç–∏—Ä—É–µ—Ç —Ç—Ä–∏ –ø–æ–¥—Ö–æ–¥–∞:
1. Zero-shot - –±–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å –±–µ–∑ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞
2. Prompt Engineering - –º–æ–¥–µ–ª—å —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º —Å–∏—Å—Ç–µ–º–Ω—ã–º –ø—Ä–æ–º–ø—Ç–æ–º
3. GRPO Trained - –æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å —Å LoRA
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from typing import List, Dict
import torch
from unsloth import FastLanguageModel

from base.data import Data
from dc_circuit.game import DCCircuitGame
from config import CircuitConfig, VerifierConfig, TrainingConfig
from base.utils import get_system_prompt


class Evaluator:
    """–û—Ü–µ–Ω—â–∏–∫ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π."""
    
    # –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã
    DEFAULT_GPU_MEMORY_UTILIZATION = 0.55
    DEFAULT_TEMPERATURE = 0.7
    DEFAULT_SAMPLES_PER_DIFFICULTY = 20
    
    def __init__(
        self,
        baseline_model: str = "unsloth/qwen3-4b-instruct-2507-unsloth-bnb-4bit",
        trained_model_path: str = "./dc_circuit_model_rl",
        samples_per_difficulty: int = DEFAULT_SAMPLES_PER_DIFFICULTY
    ):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ—Ü–µ–Ω—â–∏–∫–∞.
        
        Args:
            baseline_model: –ù–∞–∑–≤–∞–Ω–∏–µ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏
            trained_model_path: –ü—É—Ç—å –∫ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
            samples_per_difficulty: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–¥–∞—á –Ω–∞ —É—Ä–æ–≤–µ–Ω—å —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
        """
        self.baseline_model_name = baseline_model
        self.trained_model_path = trained_model_path
        self.samples_per_difficulty = samples_per_difficulty
        
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        self.circuit_config = CircuitConfig()
        self.verifier_config = VerifierConfig()
        self.training_config = TrainingConfig()
        
        # Game –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏ –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏
        self.game = DCCircuitGame(self.circuit_config, self.verifier_config)
        
    def generate_test_data(self) -> Dict[int, List[Data]]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤—Å–µ—Ö —É—Ä–æ–≤–Ω–µ–π —Å–ª–æ–∂–Ω–æ—Å—Ç–∏.
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å {difficulty: list_of_data}
        """
        print("\nüìù –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
        test_data = {}
        
        for difficulty in [1, 2]:  # –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞: —Ç–æ–ª—å–∫–æ 2 —É—Ä–æ–≤–Ω—è —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
            print(f"  –°–ª–æ–∂–Ω–æ—Å—Ç—å {difficulty}: –≥–µ–Ω–µ—Ä–∞—Ü–∏—è {self.samples_per_difficulty} –∑–∞–¥–∞—á...")
            data_list = self.game.generate(
                num_of_questions=self.samples_per_difficulty,
                difficulty=difficulty
            )
            test_data[difficulty] = data_list
            print(f"    ‚úì –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(data_list)} –∑–∞–¥–∞—á")
        
        total = sum(len(data) for data in test_data.values())
        print(f"  –í—Å–µ–≥–æ —Ç–µ—Å—Ç–æ–≤—ã—Ö –∑–∞–¥–∞—á: {total}\n")
        
        return test_data
    
    def load_model(self, model_path: str, is_trained: bool = False):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å.
        
        Args:
            model_path: –ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏
            is_trained: True –µ—Å–ª–∏ —ç—Ç–æ –æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å —Å LoRA
        
        Returns:
            (model, tokenizer)
        """
        print(f"üì• –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏: {model_path}")
        
        model, tokenizer = FastLanguageModel.from_pretrained(
            model_name=model_path,
            max_seq_length=self.training_config.max_seq_length,
            load_in_4bit=True,
            dtype=None,
            fast_inference=True,
            gpu_memory_utilization=self.DEFAULT_GPU_MEMORY_UTILIZATION
        )
        
        # –†–µ–∂–∏–º –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞
        FastLanguageModel.for_inference(model)
        
        print(f"  ‚úì –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞\n")
        return model, tokenizer
    
    def generate_answer(
        self, 
        model, 
        tokenizer, 
        question: str, 
        use_system_prompt: bool = True
    ) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏ –Ω–∞ –≤–æ–ø—Ä–æ—Å.
        
        Args:
            model: –ú–æ–¥–µ–ª—å
            tokenizer: –¢–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä
            question: –í–æ–ø—Ä–æ—Å
            use_system_prompt: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
        
        Returns:
            –û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏
        """
        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç
        if use_system_prompt:
            messages = [
                {"role": "system", "content": get_system_prompt()},
                {"role": "user", "content": question}
            ]
        else:
            # Zero-shot: —Ç–æ–ª—å–∫–æ –≤–æ–ø—Ä–æ—Å, –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç
            messages = [
                {"role": "system", "content": "You are a helpful assistant."},
                {"role": "user", "content": question}
            ]
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º chat template
        prompt = tokenizer.apply_chat_template(
            messages,
            tokenize=False,
            add_generation_prompt=True
        )
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        inputs = tokenizer([prompt], return_tensors="pt").to(model.device)
        
        outputs = model.generate(
            **inputs,
            max_new_tokens=self.training_config.max_completion_length,
            temperature=self.DEFAULT_TEMPERATURE,  
            do_sample=False,
            pad_token_id=tokenizer.eos_token_id
        )
        
        response = tokenizer.decode(outputs[0], skip_special_tokens=True)
        
        # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–º–ø—Ç –∏–∑ –æ—Ç–≤–µ—Ç–∞
        if prompt in response:
            response = response.replace(prompt, "").strip()
        
        return response
    
    def evaluate_model_on_data(
        self,
        model,
        tokenizer,
        test_data: Dict[int, List[Data]],
        method_name: str,
        use_system_prompt: bool = True
    ) -> Dict[int, Dict[str, float]]:
        """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç –º–æ–¥–µ–ª—å –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö.
        
        Args:
            model: –ú–æ–¥–µ–ª—å
            tokenizer: –¢–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä
            test_data: –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
            method_name: –ù–∞–∑–≤–∞–Ω–∏–µ –º–µ—Ç–æ–¥–∞ –¥–ª—è –≤—ã–≤–æ–¥–∞
            use_system_prompt: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å {difficulty: {"accuracy": float, "format_score": float}}
        """
        print(f"üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ: {method_name}")
        results = {}
        
        for difficulty, data_list in sorted(test_data.items()):
            correct = 0
            format_correct = 0
            total = len(data_list)
            
            for i, data in enumerate(data_list):
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
                response = self.generate_answer(
                    model, tokenizer, data.question, use_system_prompt
                )
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å
                is_correct = self.game.verify(data, response)
                if is_correct:
                    correct += 1
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞
                has_think = "<think>" in response
                has_answer = "<answer>" in response
                if has_think and has_answer:
                    format_correct += 1
                
                # –ü—Ä–æ–≥—Ä–µ—Å—Å
                if (i + 1) % 5 == 0 or (i + 1) == total:
                    print(f"  –°–ª–æ–∂–Ω–æ—Å—Ç—å {difficulty}: {i+1}/{total} –∑–∞–¥–∞—á...", end='\r')
            
            accuracy = correct / total if total > 0 else 0.0
            format_score = format_correct / total if total > 0 else 0.0
            results[difficulty] = {
                "accuracy": accuracy,
                "format_score": format_score
            }
            print(f"  –°–ª–æ–∂–Ω–æ—Å—Ç—å {difficulty}: {correct}/{total} = {accuracy:.1%} | –§–æ—Ä–º–∞—Ç: {format_correct}/{total} = {format_score:.1%}    ")
        
        # –û–±—â–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏
        avg_accuracy = sum(r["accuracy"] for r in results.values()) / len(results) if results else 0.0
        avg_format = sum(r["format_score"] for r in results.values()) / len(results) if results else 0.0
        print(f"  üìä –°—Ä–µ–¥–Ω—è—è —Ç–æ—á–Ω–æ—Å—Ç—å: {avg_accuracy:.1%} | –°—Ä–µ–¥–Ω–∏–π —Ñ–æ—Ä–º–∞—Ç: {avg_format:.1%}\n")
        
        return results
    
    def run_evaluation(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω—É—é –æ—Ü–µ–Ω–∫—É –≤—Å–µ—Ö —Ç—Ä–µ—Ö –º–µ—Ç–æ–¥–æ–≤."""
        print("================================================")
        print("                –û–¶–ï–ù–ö–ê –ú–û–î–ï–õ–ï–ô DC CIRCUIT ANALYSIS")
        print("================================================")
        
        # 1. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        test_data = self.generate_test_data()
        
        # 2. –ó–∞–≥—Ä—É–∑–∫–∞ baseline –º–æ–¥–µ–ª–∏
        baseline_model, baseline_tokenizer = self.load_model(
            self.baseline_model_name, 
            is_trained=False
        )
        
        # 3. Zero-shot –æ—Ü–µ–Ω–∫–∞ (–±–µ–∑ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞)
        print("-"*70)
        zero_shot_results = self.evaluate_model_on_data(
            baseline_model,
            baseline_tokenizer,
            test_data,
            "Zero-shot (no system prompt)",
            use_system_prompt=False
        )
        
        # 4. Prompt Engineering –æ—Ü–µ–Ω–∫–∞ (—Å —Å–∏—Å—Ç–µ–º–Ω—ã–º –ø—Ä–æ–º–ø—Ç–æ–º)
        print("-"*70)
        prompt_eng_results = self.evaluate_model_on_data(
            baseline_model,
            baseline_tokenizer,
            test_data,
            "Prompt Engineering (with system prompt)",
            use_system_prompt=True
        )
        
        # –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏
        del baseline_model, baseline_tokenizer
        torch.cuda.empty_cache()
        
        # 5. GRPO Trained –æ—Ü–µ–Ω–∫–∞ (–µ—Å–ª–∏ –º–æ–¥–µ–ª—å —Å—É—â–µ—Å—Ç–≤—É–µ—Ç)
        print("-"*70)
        grpo_results = {}
        if os.path.exists(self.trained_model_path):
            trained_model, trained_tokenizer = self.load_model(
                self.trained_model_path,
                is_trained=True
            )
            
            grpo_results = self.evaluate_model_on_data(
                trained_model,
                trained_tokenizer,
                test_data,
                "GRPO Trained (with LoRA)",
                use_system_prompt=True
            )
            
            del trained_model, trained_tokenizer
            torch.cuda.empty_cache()
        else:
            print(f"‚ö†Ô∏è  –û–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {self.trained_model_path}")
            print(f"   –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ—Ü–µ–Ω–∫—É GRPO Trained\n")
            grpo_results = {1: 0.0, 2: 0.0}
        
        # 6. –í—ã–≤–æ–¥ –∏—Ç–æ–≥–æ–≤—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        self.print_summary(zero_shot_results, prompt_eng_results, grpo_results)
        
        return {
            "zero_shot": zero_shot_results,
            "prompt_engineering": prompt_eng_results,
            "grpo_trained": grpo_results
        }
    
    def print_summary(
        self,
        zero_shot: Dict[int, Dict[str, float]],
        prompt_eng: Dict[int, Dict[str, float]],
        grpo: Dict[int, Dict[str, float]]
    ):
        """–í—ã–≤–æ–¥–∏—Ç –∏—Ç–æ–≥–æ–≤—É—é —Ç–∞–±–ª–∏—Ü—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å –∫—Ä–∞—Å–∏–≤–æ–π –¥–∏–∞–≥—Ä–∞–º–º–æ–π.
        
        Args:
            zero_shot: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã Zero-shot
            prompt_eng: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã Prompt Engineering
            grpo: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã GRPO
        """
        print("="*80)
        print(" üìä –ò–¢–û–ì–û–í–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´")
        print("="*80)
        print()
        
        # –¢–∞–±–ª–∏—Ü–∞ —Ç–æ—á–Ω–æ—Å—Ç–∏
        print("üéØ –¢–û–ß–ù–û–°–¢–¨ –û–¢–í–ï–¢–û–í:")
        print("| –ú–µ—Ç–æ–¥                  | –°–ª–æ–∂–Ω–æ—Å—Ç—å 1 | –°–ª–æ–∂–Ω–æ—Å—Ç—å 2 | –°—Ä–µ–¥–Ω–µ–µ |")
        print("|------------------------|-------------|-------------|---------|")
        
        # Zero-shot
        avg_zero_acc = sum(zero_shot[d]["accuracy"] for d in zero_shot) / len(zero_shot) if zero_shot else 0.0
        print(f"| Zero-shot              | {zero_shot.get(1, {}).get('accuracy', 0.0):>10.1%} | "
              f"{zero_shot.get(2, {}).get('accuracy', 0.0):>10.1%} | {avg_zero_acc:>6.1%} |")
        
        # Prompt Engineering
        avg_pe_acc = sum(prompt_eng[d]["accuracy"] for d in prompt_eng) / len(prompt_eng) if prompt_eng else 0.0
        print(f"| Prompt Engineering     | {prompt_eng.get(1, {}).get('accuracy', 0.0):>10.1%} | "
              f"{prompt_eng.get(2, {}).get('accuracy', 0.0):>10.1%} | {avg_pe_acc:>6.1%} |")
        
        # GRPO Trained
        avg_grpo_acc = sum(grpo[d]["accuracy"] for d in grpo) / len(grpo) if grpo else 0.0
        print(f"| GRPO Trained           | {grpo.get(1, {}).get('accuracy', 0.0):>10.1%} | "
              f"{grpo.get(2, {}).get('accuracy', 0.0):>10.1%} | {avg_grpo_acc:>6.1%} |")
        
        print()
        
        # –¢–∞–±–ª–∏—Ü–∞ —Ñ–æ—Ä–º–∞—Ç–∞
        print("üìù –ü–†–ê–í–ò–õ–¨–ù–´–ô –§–û–†–ú–ê–¢ –û–¢–í–ï–¢–û–í:")
        print("| –ú–µ—Ç–æ–¥                  | –°–ª–æ–∂–Ω–æ—Å—Ç—å 1 | –°–ª–æ–∂–Ω–æ—Å—Ç—å 2 | –°—Ä–µ–¥–Ω–µ–µ |")
        print("|------------------------|-------------|-------------|---------|")
        
        # Zero-shot format
        avg_zero_fmt = sum(zero_shot[d]["format_score"] for d in zero_shot) / len(zero_shot) if zero_shot else 0.0
        print(f"| Zero-shot              | {zero_shot.get(1, {}).get('format_score', 0.0):>10.1%} | "
              f"{zero_shot.get(2, {}).get('format_score', 0.0):>10.1%} | {avg_zero_fmt:>6.1%} |")
        
        # Prompt Engineering format
        avg_pe_fmt = sum(prompt_eng[d]["format_score"] for d in prompt_eng) / len(prompt_eng) if prompt_eng else 0.0
        print(f"| Prompt Engineering     | {prompt_eng.get(1, {}).get('format_score', 0.0):>10.1%} | "
              f"{prompt_eng.get(2, {}).get('format_score', 0.0):>10.1%} | {avg_pe_fmt:>6.1%} |")
        
        # GRPO Trained format
        avg_grpo_fmt = sum(grpo[d]["format_score"] for d in grpo) / len(grpo) if grpo else 0.0
        print(f"| GRPO Trained           | {grpo.get(1, {}).get('format_score', 0.0):>10.1%} | "
              f"{grpo.get(2, {}).get('format_score', 0.0):>10.1%} | {avg_grpo_fmt:>6.1%} |")
        
        print()
        
        # –ö—Ä–∞—Å–∏–≤–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞
        self.print_visual_chart(avg_zero_acc, avg_pe_acc, avg_grpo_acc, avg_zero_fmt, avg_pe_fmt, avg_grpo_fmt)
    
    def print_visual_chart(self, acc_zero, acc_pe, acc_grpo, fmt_zero, fmt_pe, fmt_grpo):
        """–°–æ–∑–¥–∞–µ—Ç –∫—Ä–∞—Å–∏–≤—É—é ASCII –¥–∏–∞–≥—Ä–∞–º–º—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤."""
        print("üìà –í–ò–ó–£–ê–õ–¨–ù–ê–Ø –î–ò–ê–ì–†–ê–ú–ú–ê –†–ï–ó–£–õ–¨–¢–ê–¢–û–í:")
        print("="*60)
        print()
        
        # –î–∏–∞–≥—Ä–∞–º–º–∞ —Ç–æ—á–Ω–æ—Å—Ç–∏
        print("üéØ –¢–û–ß–ù–û–°–¢–¨ –û–¢–í–ï–¢–û–í:")
        self._print_bar_chart([
            ("Zero-shot", acc_zero),
            ("Prompt Eng", acc_pe), 
            ("GRPO Trained", acc_grpo)
        ])
        
        print()
        
        # –î–∏–∞–≥—Ä–∞–º–º–∞ —Ñ–æ—Ä–º–∞—Ç–∞
        print("üìù –ü–†–ê–í–ò–õ–¨–ù–´–ô –§–û–†–ú–ê–¢:")
        self._print_bar_chart([
            ("Zero-shot", fmt_zero),
            ("Prompt Eng", fmt_pe),
            ("GRPO Trained", fmt_grpo)
        ])
        
        print()
        
        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —É–ª—É—á—à–µ–Ω–∏–π
        print("üìä –£–õ–£–ß–®–ï–ù–ò–Ø:")
        if acc_pe > acc_zero:
            print(f"‚úÖ Prompt Engineering —É–ª—É—á—à–∏–ª —Ç–æ—á–Ω–æ—Å—Ç—å –Ω–∞ {acc_pe - acc_zero:.1%}")
        else:
            print(f"‚ùå Prompt Engineering —Å–Ω–∏–∑–∏–ª —Ç–æ—á–Ω–æ—Å—Ç—å –Ω–∞ {acc_zero - acc_pe:.1%}")
            
        if acc_grpo > acc_pe:
            print(f"üöÄ GRPO –æ–±—É—á–µ–Ω–∏–µ —É–ª—É—á—à–∏–ª —Ç–æ—á–Ω–æ—Å—Ç—å –Ω–∞ {acc_grpo - acc_pe:.1%}")
        else:
            print(f"‚ö†Ô∏è  GRPO –æ–±—É—á–µ–Ω–∏–µ —Å–Ω–∏–∑–∏–ª —Ç–æ—á–Ω–æ—Å—Ç—å –Ω–∞ {acc_pe - acc_grpo:.1%}")
            
        if fmt_pe > fmt_zero:
            print(f"‚úÖ Prompt Engineering —É–ª—É—á—à–∏–ª —Ñ–æ—Ä–º–∞—Ç –Ω–∞ {fmt_pe - fmt_zero:.1%}")
        else:
            print(f"‚ùå Prompt Engineering —Å–Ω–∏–∑–∏–ª —Ñ–æ—Ä–º–∞—Ç –Ω–∞ {fmt_zero - fmt_pe:.1%}")
            
        if fmt_grpo > fmt_pe:
            print(f"üöÄ GRPO –æ–±—É—á–µ–Ω–∏–µ —É–ª—É—á—à–∏–ª —Ñ–æ—Ä–º–∞—Ç –Ω–∞ {fmt_grpo - fmt_pe:.1%}")
        else:
            print(f"‚ö†Ô∏è  GRPO –æ–±—É—á–µ–Ω–∏–µ —Å–Ω–∏–∑–∏–ª —Ñ–æ—Ä–º–∞—Ç –Ω–∞ {fmt_pe - fmt_grpo:.1%}")
    
    def _print_bar_chart(self, data):
        """–°–æ–∑–¥–∞–µ—Ç ASCII bar chart."""
        max_val = max(item[1] for item in data) if data else 0
        if max_val == 0:
            max_val = 1
        
        for name, value in data:
            bar_length = int(value * 30 / max_val) if max_val > 0 else 0
            bar = "‚ñà" * bar_length + "‚ñë" * (30 - bar_length)
            print(f"  {name:<12} ‚îÇ{bar}‚îÇ {value:.1%}")
    


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è."""
    evaluator = Evaluator(
        baseline_model="unsloth/qwen3-4b-instruct-2507-unsloth-bnb-4bit",
        trained_model_path="./dc_circuit_model_rl",
        samples_per_difficulty=20 
    )
    
    results = evaluator.run_evaluation()
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Ñ–∞–π–ª
    import json
    with open("evaluation_results.json", "w") as f:
        json.dump(results, f, indent=2)
    print("üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ evaluation_results.json")


if __name__ == "__main__":
    main()