# Система логирования LLM для GRPO обучения

## Описание

Система автоматически записывает все взаимодействия с LLM во время обучения GRPO:

- **Входы (промпты)** - что подается на вход модели
- **Выходы (completions)** - что отвечает модель  
- **Rewards** - оценки качества ответов
- **Метаданные** - дополнительная информация

## Файлы логов

### 1. Потоковое логирование (`llm_logs_YYYYMMDD_HHMMSS.jsonl`)
- Записывается в реальном времени
- Формат: JSON Lines (одна запись на строку)
- Содержит все взаимодействия по мере их возникновения

### 2. Полное логирование (`llm_logs_complete_YYYYMMDD_HHMMSS.json`)
- Создается в конце обучения
- Формат: JSON массив
- Содержит все записи в структурированном виде

## Структура записи лога

```json
{
  "timestamp": "2025-10-13T11:30:45.123456",
  "prompt": "Вопрос о электрической цепи...",
  "completion": "Ответ модели...",
  "reward": 1.8,
  "metadata": {
    "correct_answer": "2.5",
    "accuracy_score": 0.9,
    "batch_idx": 0
  }
}
```

## Анализ логов

### Использование скрипта анализа:

```bash
python analyze_llm_logs.py llm_logs_20251013_113045.jsonl
```

### Что анализируется:

1. **Распределение rewards** - статистика качества ответов
2. **Длина промптов и ответов** - анализ сложности задач
3. **Качество ответов** - количество высококачественных ответов
4. **Временные метки** - анализ прогресса обучения

### Выходные файлы:

- `analysis_output_reward_distribution.png` - график распределения rewards
- `analysis_output_samples.json` - примеры логов для анализа
- Консольный вывод со статистикой

## Примеры использования

### Просмотр логов в реальном времени:
```bash
tail -f llm_logs_20251013_113045.jsonl
```

### Анализ конкретного файла:
```bash
python analyze_llm_logs.py llm_logs_20251013_113045.jsonl --output my_analysis
```

### Экспорт примеров:
```bash
python analyze_llm_logs.py llm_logs_20251013_113045.jsonl --samples 50
```

## Автоматическое сохранение

Логи автоматически сохраняются в следующих случаях:

1. **Успешное завершение обучения**
2. **Прерывание (Ctrl+C)**
3. **Ошибка во время обучения**

## Настройка

В коде можно настроить:

- **Формат временных меток** - в `log_llm_interaction()`
- **Дополнительные метаданные** - в `reward_function()`
- **Частота сохранения** - в `log_llm_interaction()`

## Мониторинг обучения

Система позволяет:

- Отслеживать качество ответов модели в реальном времени
- Анализировать прогресс обучения
- Выявлять проблемы в процессе обучения
- Сравнивать разные сессии обучения
