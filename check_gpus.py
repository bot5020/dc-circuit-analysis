#!/usr/bin/env python3
"""–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö GPU"""

import torch

print("="*80)
print("üîç –ü–†–û–í–ï–†–ö–ê GPU")
print("="*80)

# –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ GPU
num_gpus = torch.cuda.device_count()
print(f"\n–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ GPU: {num_gpus}")

if num_gpus == 0:
    print("‚ùå GPU –Ω–µ –Ω–∞–π–¥–µ–Ω–æ!")
elif num_gpus == 1:
    print("‚ö†Ô∏è  –ù–∞–π–¥–µ–Ω–∞ –û–î–ù–ê GPU - –Ω–µ–ª—å–∑—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å DDP –¥–ª—è 2 GPU")
    print("   –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –æ–±—ã—á–Ω—ã–π rl_trainer.py")
else:
    print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {num_gpus} GPU - –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å DDP")

# –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–∞–∂–¥–æ–π GPU
print("\n" + "-"*80)
for i in range(num_gpus):
    props = torch.cuda.get_device_properties(i)
    print(f"\nGPU {i}:")
    print(f"  –ù–∞–∑–≤–∞–Ω–∏–µ: {props.name}")
    print(f"  –ü–∞–º—è—Ç—å: {props.total_memory / 1024**3:.1f} GB")
    print(f"  Compute: {props.major}.{props.minor}")

# CUDA_VISIBLE_DEVICES
import os
cuda_visible = os.environ.get('CUDA_VISIBLE_DEVICES', '–Ω–µ –∑–∞–¥–∞–Ω–æ')
print(f"\nCUDA_VISIBLE_DEVICES: {cuda_visible}")

print("\n" + "="*80)
if num_gpus == 1:
    print("üí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–Ø: –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ training/rl_trainer.py (–±–µ–∑ DDP)")
    print("="*80)
elif num_gpus >= 2:
    print("üí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–Ø: –ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å training/rl_trainer_2gpu.py")
    print("="*80)
else:
    print("‚ùå GPU –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
    print("="*80)
